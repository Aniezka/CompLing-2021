{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\") + ['это', \"тебе\", 'очень', 'ещё', 'просто', 'вообще']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    14412\n",
       "toxic      14412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9761</td>\n",
       "      <td>Я всегда с клепками беру, что бы мозг не ебсти...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12685</td>\n",
       "      <td>Только тихо. Первое правило тайной комнаты...\\n</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12792</td>\n",
       "      <td>А уехать они должны тоже с котом или ко идёт в...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8335</td>\n",
       "      <td>У нас все прыгали исключительно на своих параш...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13067</td>\n",
       "      <td>сомнительно, что все критично подорожает. Для ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            comment  toxic\n",
       "0   9761  Я всегда с клепками беру, что бы мозг не ебсти...    1.0\n",
       "1  12685    Только тихо. Первое правило тайной комнаты...\\n    0.0\n",
       "2  12792  А уехать они должны тоже с котом или ко идёт в...    0.0\n",
       "3   8335  У нас все прыгали исключительно на своих параш...    0.0\n",
       "4  13067  сомнительно, что все критично подорожает. Для ...    0.0"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=russian_stopwords)\n",
    "X = vectorizer.fit_transform(train.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(s: str):\n",
    "    tokens = list(razdel.tokenize(s))\n",
    "    return [_.text for _ in tokens]\n",
    "\n",
    "cv = TfidfVectorizer(tokenizer=tokenization, stop_words=russian_stopwords)\n",
    "X_razdel = cv.fit_transform(train.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_test_razdel = vectorizer.transform(test.comment), cv.transform(test.comment)\n",
    "\n",
    "y = train.toxic\n",
    "y_test = test.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.98      0.87       946\n",
      "         1.0       0.93      0.47      0.62       496\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.86      0.72      0.75      1442\n",
      "weighted avg       0.83      0.81      0.78      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, class_weight='unbalanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.98      0.87       946\n",
      "         1.0       0.92      0.51      0.65       496\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.85      0.74      0.76      1442\n",
      "weighted avg       0.83      0.81      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, class_weight='unbalanced')\n",
    "clf.fit(X_razdel, y)\n",
    "preds = clf.predict(X_test_razdel)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии исходя из результатов токенизатор razdel.tokenize немного улучшил результат по f1 метрикам относительно токенизатора по умолчанию TfidfVectorizer. То есть razdel.tokenize отработал лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"я и ты\",\n",
    "    \"ты и я\",\n",
    "    \"я, я и только я\",\n",
    "    \"только не я\",\n",
    "    \"он\"\n",
    "]\n",
    "\n",
    "# удалим пунктуацию\n",
    "data = [s.translate(str.maketrans('', '', string.punctuation)) for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: i for i, word in enumerate(set([word for s in data for word in s.split()]))}\n",
    "words_count = len([i for s in data for i in s.split()])\n",
    "N = len(data)\n",
    "\n",
    "DF = defaultdict(int) \n",
    "for word in set(word_index.keys()):\n",
    "    for text in data:\n",
    "        words = text.split()\n",
    "        if word in words:\n",
    "            DF[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.074, 0, 0.17, 0, 0.305],\n",
       " [0, 0.074, 0, 0.17, 0, 0.305],\n",
       " [0.183, 0.134, 0, 0.102, 0, 0],\n",
       " [0.305, 0.074, 0.536, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1.609, 0]]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = [[0 for i in range(len(word_index))] for j in range(len(data))]\n",
    "\n",
    "for doc in range(len(data)):\n",
    "    tokens = data[doc].split()\n",
    "    counter = Counter(tokens)\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token] / len(tokens)\n",
    "        df = DF[token]\n",
    "        idf = np.log(N/(df))\n",
    "        tf_idf[doc][word_index[token]] = round(tf*idf, 3)\n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>только</th>\n",
       "      <th>я</th>\n",
       "      <th>не</th>\n",
       "      <th>и</th>\n",
       "      <th>он</th>\n",
       "      <th>ты</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я я и только я</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                только      я     не      и     он     ты\n",
       "я и ты           0.000  0.074  0.000  0.170  0.000  0.305\n",
       "ты и я           0.000  0.074  0.000  0.170  0.000  0.305\n",
       "я я и только я   0.183  0.134  0.000  0.102  0.000  0.000\n",
       "только не я      0.305  0.074  0.536  0.000  0.000  0.000\n",
       "он               0.000  0.000  0.000  0.000  1.609  0.000"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tf_idf, columns=word_index.keys())\n",
    "df = df.set_index(pd.Series(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.96      0.87       962\n",
      "         1.0       0.86      0.50      0.64       480\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.83      0.73      0.75      1442\n",
      "weighted avg       0.82      0.81      0.79      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=14, max_df=0.37, stop_words=russian_stopwords, max_features=10000, use_idf=True)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)\n",
    "\n",
    "clf = LogisticRegression(C=1, class_weight='unbalanced')\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "preds_log = [x[1] for x in clf.predict_proba(X_test)]\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.94      0.86       962\n",
      "         1.0       0.81      0.53      0.64       480\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.81      0.73      0.75      1442\n",
      "weighted avg       0.80      0.80      0.79      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=15, max_df=0.2, max_features=100000, stop_words=russian_stopwords, analyzer=\"word\")\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced_subsample')\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "clf.fit(X, y)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "preds_nb = [x[1] for x in clf.predict_proba(X_test)]\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим топ 10 самых токсичных текста из каждого классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nb = zip(preds_nb, test.comment)\n",
    "res_log = zip(preds_log, test.comment)\n",
    "\n",
    "res_nb = sorted(res_nb, key=lambda x: x[0], reverse=True)\n",
    "res_log = sorted(res_log, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['У-ух, ненавижу, блядь, хохлов.\\n',\n",
       " 'Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!\\n',\n",
       " 'Ебать вы тупые дебилы, ой блять\\n',\n",
       " 'Опять хохлы из киберсотни на куриную косточку капчуют.\\n',\n",
       " 'Всех же так волнует,что там у хохлов?\\n',\n",
       " 'Хохлы то да разъезжаются ты прав.\\n',\n",
       " 'Какие же хохлы незалежные дегенераты, пиздец просто.\\n',\n",
       " 'если хохлы это лахта,то они существуют страно что еще накрутчик раги не врубили\\n',\n",
       " 'Свин, иди нахуй. Можно хоть один тред без политоты? Даже тебя хуеосить не хочется, давай лучше про няшек-фигуристок говорить.\\n',\n",
       " 'НУ ЧО СУКА ПРОСИЛ СКЕТЧИ? ПРОСИЛ? ПОЛУЧАЙ БЛЯДЬ!!\\n']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[1] for i in res_log[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Да тупая баба. Видос недавно был: мразь какая то девку у прилавка схватил и говорит отдай деньги, а то я ее зарежу. А ебанутая сука ему говорит Ах перестань хулиганить. И даже когда он телку ножом хуярить начал, она его из ведрышка поливала и шваброй стукнуть пыталась. Пока он ее саму ножом не уебал, до тупой суки не доходило, что при ней человека убивали. Какая слабина, диванные воены? Отдайте все что нужно и вызывайте полицию. Рэмбы комнатные.\\n',\n",
       " 'Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!\\n',\n",
       " 'Хохлы не люди. Их нужно обязательно бить, унижать, ссать на лицо. Если же пытаться вести с ними хорошо, как это делали в СССР и докрымской России, то они начинают наглеть и безобразничать. Как и все дегенераты, хохлы вежливое отношение принимают за слабость. Увидел хохлы, плюнь ему в рожу и пни под зад сапогом. Ради счастья всего человечества.\\n',\n",
       " 'Какую тему? То, что жиды пидорасы? По-моему это ты пришёл в тред, оскорбился что тут хохлов не обсуждают и начал разводить разговоры о своей мусорной странёнке. Кто ещё тему перекрывает, долбоёбина, иди таблеток наебни, или я санитаров вызываю.\\n',\n",
       " 'Целью встречи стали переговоры о сохранении поставок газа А что, у него есть полномочия вести такие переговоры? Сука блядский цирк. Какие же хохлы дегенераты, пиздец просто\\n',\n",
       " 'Ебать вы тупые дебилы, ой блять\\n',\n",
       " 'Чтобы Астану назвали Нурсултаном. А если недоволен,что у Пахомии так много земель, ну кто же виноват что ареал обитания твоих дидов это кыргызкая степь. И посмотри чьих дидов погибло в WOW больше всего и это будут хохлы, русня и белорусы. А казахов около процента. Так что пиздуй в свой нурсулстан и невыебывайся, чмонька.\\n',\n",
       " '2:30 - малолетнему дебилу открылся дзен и пришло просветление. Лучше поздно, чем никогда. 5:45 - верит рассказам сокамерников о своей невиновности. Ну, дебил малолетний, ничего не поделаешь. Хотя он себя тоже не считает в чём-то виноватым. у нас плохие законы, по ним сажают за наркотики А вот с этого орнул. Какой же он дегенерат. Короче, этому петуху место в изоляции.\\n',\n",
       " 'Да не буду я тебе нихуя искать, общеизвестная инфа. В своих знаниях и так убежден, а если ты просто хочешь активно не верить - мне похуй. Главный модуль американской части МКС тоже создан в России - и хуле? Короче маму твою ебал.',\n",
       " 'Посмотрел и что дальше? Тред и о мертвишко-тян есть, понятно, что не блоггер, но активность же идёт, значит люди хотят о ней говорить и не только видимо на двачах. А есть Ебатории тред в котором все ноунеймы по сути, кроме ВжЛинка, но он подходит под тематику этого треда, Озон был уже. Есть тред про Юлию Туррета, тоже наверное охуееную популярность имеет, да? Не переоценивай fag\\n']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[1] for i in res_nb[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпадающие тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ебать вы тупые дебилы, ой блять\\n',\n",
       " 'Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!\\n'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i[1] for i in res_log[:10]]).intersection(set([i[1] for i in res_nb[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Совпадает всего 2 текста:\n",
    "\n",
    "'Ебать вы тупые дебилы, ой блять\\n'\n",
    "\n",
    "'Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!\\n'\n",
    "\n",
    "##### но зато все выделенные тексты можно назвать токсичными. Стоит также заметить, что логистическая регрессия определила самыми токсичными довольно короткие тесты, в отличие от наивного байесовского классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=17, max_df=0.4, stop_words=russian_stopwords, max_features=10000, use_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "tokens = vectorizer.get_feature_names()\n",
    "\n",
    "X_test = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression(C=1, class_weight='unbalanced')\n",
    "clf_log.fit(X, y)\n",
    "\n",
    "clf_log_coef = clf_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(X, y)\n",
    "\n",
    "clf_dt_coef = clf_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X, y)\n",
    "\n",
    "clf_nb_coef = clf_nb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X, y)\n",
    "\n",
    "clf_rf_coef = clf_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим топ 5 самых токсичных слов для каждого классификатора:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['хохлы', 'хохлов', 'дебил', 'сука', 'тупые']\n"
     ]
    }
   ],
   "source": [
    "res_log = zip(clf_log_coef[0], tokens)\n",
    "res_log = sorted(res_log, key=lambda x: x[0], reverse=True)\n",
    "print([i[1] for i in res_log[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['хохлы', 'хохлов', 'нахуй', 'блядь', 'блять']\n"
     ]
    }
   ],
   "source": [
    "res_dt = zip(clf_dt_coef, tokens)\n",
    "res_dt = sorted(res_dt, key=lambda x: x[0], reverse=True)\n",
    "print([i[1] for i in res_dt[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный байесовский классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['хохлы', 'почему', 'хохлов', 'нахуй', 'хуй']\n"
     ]
    }
   ],
   "source": [
    "res_nb = zip(clf_nb_coef[0], tokens)\n",
    "res_nb = sorted(res_nb, key=lambda x: x[0], reverse=True)\n",
    "print([i[1] for i in res_nb[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['хохлы', 'хохлов', 'нахуй', 'сука', 'хуй']\n"
     ]
    }
   ],
   "source": [
    "res_rf = zip(clf_rf_coef, tokens)\n",
    "res_rf = sorted(res_rf, key=lambda x: x[0], reverse=True)\n",
    "print([i[1] for i in res_rf[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что сильными критериями токсичности классификаторы выделяют почти одни и те же слова, которые представляют собой нецензурную лексику. Я дополнила список стоп слов, которых не было в стандартном наборе стоп слов для русского языка nltk (добавила слова, которые на мой взгляд не несут смысловой нагрузки)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
