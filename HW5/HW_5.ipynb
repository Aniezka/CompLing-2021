{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50eaf934",
   "metadata": {},
   "source": [
    "# Домашнее задание  № 5. Матричные разложения/Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3d2c7",
   "metadata": {},
   "source": [
    "### Задание № 1 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cc584",
   "metadata": {},
   "source": [
    "Попробуйте матричные разложения с 5 классификаторами - SGDClassifier, KNeighborsClassifier,  RandomForest, ExtraTreesClassifier (про него подробнее почитайте в документации, он похож на RF). Используйте и NMF и SVD. Сравните результаты на кросс-валидации и выберите лучшее сочетание.\n",
    "\n",
    "В итоге у вас должно получиться, как минимум 10 моделей (два разложения на каждый классификатор). Используйте 1 и те же параметры кросс-валидации. Параметры векторизации, параметры K в матричных разложениях, параметры классификаторов могут быть разными между экспериментами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84bce57",
   "metadata": {},
   "source": [
    "Можете взять поменьше данных, если все будет обучаться слишком долго (не ставьте параметр K слишком большим в NMF, иначе точно будет слишком долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd76c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ff730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aef4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim_models\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f0f04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим лемматизацию\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
    "    return ' '.join(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2cec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('avito_category_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a779526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd0566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description_norm'] = data['description'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97738f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f290bf",
   "metadata": {},
   "source": [
    "### Сначала рассмотрим SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0be01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svd_sgd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "pipeline_svd_kneir = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_svd_rf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=10))\n",
    "])\n",
    "\n",
    "pipeline_svd_etc = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('svd', TruncatedSVD(500)),\n",
    "    ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94da4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_table(X, y, pipeline, N=6):\n",
    "    # зафиксируем порядок классов\n",
    "    labels = list(set(y))\n",
    "    \n",
    "    # метрики отдельных фолдов будет хранить в табличке\n",
    "    fold_metrics = pd.DataFrame(index=labels)\n",
    "    # дополнительно также соберем таблицу ошибок\n",
    "    errors = np.zeros((len(labels), len(labels)))\n",
    "    \n",
    "    # создаем стратегию кросс-валидации\n",
    "    # shuffle=True (перемешивание) - часто критично важно указать\n",
    "    # т.к. данные могут быть упорядочены и модель на этом обучится\n",
    "    kfold = StratifiedKFold(n_splits=N, shuffle=True, )\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        # fit-predict как и раньше, но сразу пайплайном\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "        preds = pipeline.predict(X[test_index])\n",
    "        \n",
    "        # записываем метрику и индекс фолда\n",
    "        fold_metrics[f'precision_{i}'] = precision_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'recall_{i}'] = recall_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
    "        errors += confusion_matrix(y[test_index], preds, labels=labels, normalize='true')\n",
    "    \n",
    "    # таблица для усредненных значений\n",
    "    # тут мы берем колонки со значениями и усредняем их\n",
    "    # часто также все метрики сразу суммируют и в конце просто делят на количество фолдов\n",
    "    # но мы тут помимо среднего также хотим посмотреть на стандартное отклонение\n",
    "    # чтобы понять как сильно варьируются оценки моделей\n",
    "    result = pd.DataFrame(index=labels)\n",
    "    result['precision'] = fold_metrics[[f'precision_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['precision_std'] = fold_metrics[[f'precision_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['recall'] = fold_metrics[[f'recall_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['recall_std'] = fold_metrics[[f'recall_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['f1_std'] = fold_metrics[[f'f1_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    # добавим одну колонку со средним по всем классам\n",
    "    result.loc['mean'] = result.mean().round(2)\n",
    "    # проценты ошибок просто усредняем\n",
    "    errors /= N\n",
    "    \n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a381d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_svd_sgd, errors_svd_sgd = eval_table(data['description_norm'], data['category_name'], pipeline_svd_sgd)\n",
    "metrics_svd_kneir, errors_svd_kneir = eval_table(data['description_norm'], data['category_name'], pipeline_svd_kneir)\n",
    "metrics_svd_rf, errors_svd_rf = eval_table(data['description_norm'], data['category_name'], pipeline_svd_rf)\n",
    "metrics_svd_etc, errors_svd_etc = eval_table(data['description_norm'], data['category_name'], pipeline_svd_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c1ae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Телефоны</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Одежда, обувь, аксессуары</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Детская одежда и обувь</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ремонт и строительство</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Мебель и интерьер</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Товары для детей и игрушки</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Бытовая техника</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Квартиры</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Предложение услуг</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Автомобили</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            precision  precision_std  recall  recall_std  \\\n",
       "Телефоны                         0.77           0.10    0.73        0.05   \n",
       "Одежда, обувь, аксессуары        0.69           0.01    0.78        0.04   \n",
       "Детская одежда и обувь           0.75           0.05    0.73        0.02   \n",
       "Ремонт и строительство           0.51           0.13    0.41        0.07   \n",
       "Мебель и интерьер                0.65           0.06    0.59        0.08   \n",
       "Товары для детей и игрушки       0.69           0.08    0.60        0.09   \n",
       "Бытовая техника                  0.52           0.08    0.43        0.14   \n",
       "Квартиры                         0.96           0.02    0.95        0.02   \n",
       "Предложение услуг                0.73           0.06    0.76        0.07   \n",
       "Автомобили                       0.80           0.11    0.88        0.02   \n",
       "mean                             0.71           0.07    0.69        0.06   \n",
       "\n",
       "                              f1  f1_std  \n",
       "Телефоны                    0.75    0.03  \n",
       "Одежда, обувь, аксессуары   0.73    0.02  \n",
       "Детская одежда и обувь      0.74    0.03  \n",
       "Ремонт и строительство      0.45    0.09  \n",
       "Мебель и интерьер           0.62    0.06  \n",
       "Товары для детей и игрушки  0.64    0.08  \n",
       "Бытовая техника             0.46    0.11  \n",
       "Квартиры                    0.95    0.02  \n",
       "Предложение услуг           0.74    0.04  \n",
       "Автомобили                  0.84    0.06  \n",
       "mean                        0.69    0.05  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d140f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=list(itertools.chain([\"model\"], metrics_svd_rf.columns)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9899e6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier svd</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier svd</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest svd</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesClassifier svd</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  precision  precision_std  recall  recall_std  \\\n",
       "0         SGDClassifier svd       0.71           0.07    0.69        0.06   \n",
       "1  KNeighborsClassifier svd       0.48           0.07    0.39        0.07   \n",
       "2          RandomForest svd       0.75           0.14    0.36        0.05   \n",
       "3  ExtraTreesClassifier svd       0.67           0.22    0.21        0.03   \n",
       "\n",
       "     f1  f1_std  \n",
       "0  0.69    0.05  \n",
       "1  0.41    0.06  \n",
       "2  0.39    0.06  \n",
       "3  0.20    0.04  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[0] = (list(['SGDClassifier svd'] + list(metrics_svd_sgd.loc['mean'].values)))\n",
    "res.loc[1] = (list(['KNeighborsClassifier svd'] + list(metrics_svd_kneir.loc['mean'].values)))\n",
    "res.loc[2] = (list(['RandomForest svd'] + list(metrics_svd_rf.loc['mean'].values)))\n",
    "res.loc[3] = (list(['ExtraTreesClassifier svd'] + list(metrics_svd_etc.loc['mean'].values)))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123a6b2",
   "metadata": {},
   "source": [
    "### Теперь рассмотрим NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39322666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nmf_sgd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('decomposition', NMF(100)),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "pipeline_nmf_kneir = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('decomposition', NMF(100)),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline_nmf_rf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('decomposition', NMF(100)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=10))\n",
    "])\n",
    "\n",
    "pipeline_nmf_etc = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), min_df=5, max_df=0.6)),\n",
    "    ('decomposition', NMF(100)),\n",
    "    ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbeb57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_nmf_sgd, errors_nmf_sgd = eval_table(data['description_norm'], data['category_name'], pipeline_nmf_sgd)\n",
    "metrics_nmf_kneir, errors_nmf_kneir = eval_table(data['description_norm'], data['category_name'], pipeline_nmf_kneir)\n",
    "metrics_nmf_rf, errors_nmf_rf = eval_table(data['description_norm'], data['category_name'], pipeline_nmf_rf)\n",
    "metrics_nmf_etc, errors_nmf_etc = eval_table(data['description_norm'], data['category_name'], pipeline_nmf_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9449fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[4] = (list(['SGDClassifier nmf'] + list(metrics_nmf_sgd.loc['mean'].values)))\n",
    "res.loc[5] = (list(['KNeighborsClassifier nmf'] + list(metrics_nmf_kneir.loc['mean'].values)))\n",
    "res.loc[6] = (list(['RandomForest nmf'] + list(metrics_nmf_rf.loc['mean'].values)))\n",
    "res.loc[7] = (list(['ExtraTreesClassifier nmf'] + list(metrics_nmf_etc.loc['mean'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd84b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier svd</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier svd</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest svd</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesClassifier svd</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier nmf</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier nmf</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest nmf</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier nmf</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  precision  precision_std  recall  recall_std  \\\n",
       "0         SGDClassifier svd       0.71           0.07    0.69        0.06   \n",
       "1  KNeighborsClassifier svd       0.48           0.07    0.39        0.07   \n",
       "2          RandomForest svd       0.75           0.14    0.36        0.05   \n",
       "3  ExtraTreesClassifier svd       0.67           0.22    0.21        0.03   \n",
       "4         SGDClassifier nmf       0.60           0.20    0.48        0.11   \n",
       "5  KNeighborsClassifier nmf       0.42           0.08    0.37        0.06   \n",
       "6          RandomForest nmf       0.69           0.12    0.51        0.05   \n",
       "7  ExtraTreesClassifier nmf       0.71           0.16    0.35        0.05   \n",
       "\n",
       "     f1  f1_std  \n",
       "0  0.69    0.05  \n",
       "1  0.41    0.06  \n",
       "2  0.39    0.06  \n",
       "3  0.20    0.04  \n",
       "4  0.48    0.08  \n",
       "5  0.38    0.06  \n",
       "6  0.54    0.05  \n",
       "7  0.38    0.06  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d857f58",
   "metadata": {},
   "source": [
    "### Результат:\n",
    "\n",
    "Лучшее сочетание по критерию средней F1 меры - это SVD разложение и SGD классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dc17d",
   "metadata": {},
   "source": [
    "### Задание № 2 (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e374bc",
   "metadata": {},
   "source": [
    "В Gensim тоже можно добавить нграммы и tfidf. Постройте 1 модель без них (как в семинаре) и еще 3 модели (1 с нграммами, 1 с tfidf и 1 с нграммами и с tfidf). Сранивте качество с помощью метрик (перплексия, когерентность) и на глаз. Определите лучшую модель. Для каждой модели выберите 1 самую красивую на ваш взгляд тему.\n",
    "\n",
    "Используйте данные википедии из семинара. Можете взять поменьше данных, если все обучается долго.\n",
    "\n",
    "Важное требование - получившиеся модели не должны быть совсем плохими. Если хороших тем не получается, попробуйте настроить гиперпараметры, отфильтровать словарь по-другому. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d62e8",
   "metadata": {},
   "source": [
    "Нграммы добавляются вот так (перед созданиеv словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3da7f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = [text.split() for text in texts]\n",
    "# ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4) # threshold можно подбирать\n",
    "# p = gensim.models.phrases.Phraser(ph)\n",
    "# ngrammed_texts = p[texts]  \n",
    "\n",
    "# ! не забудьте, что далее вам нужно будет использовать ngrammed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a1a38",
   "metadata": {},
   "source": [
    "!! В модели с нграммами вначале посмотрите, что получается после преобразования\n",
    "Если вы выведите несколько первых текстов в ngrammed_texts, то там должно быть что-то такое:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b762f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [text for text in ngrammed_texts[:3]]\n",
    "# >> [['новостройка',\n",
    "#   'нижегородский_область', # нграм\n",
    "#   'новостро́йка',\n",
    "#   '—',\n",
    "#   'сельский',\n",
    "#   'посёлок',\n",
    "#   'в',\n",
    "#   'дивеевский_район', # нграм\n",
    "#   'нижегородский_область', #нграмм\n",
    "#   'входить',\n",
    "#   'в',\n",
    "#   'состав_сатисский', #нграмм\n",
    "#   'сельсовет',\n",
    "#   'посёлок',\n",
    "#   'расположить',\n",
    "#   'в',\n",
    "#   '12,5',\n",
    "#   'километр',\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d581321",
   "metadata": {},
   "source": [
    "Если вы не видите нграммов, то попробуйте изменить параметр threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf5cac",
   "metadata": {},
   "source": [
    "Tfidf добавляется вот так (после векторизации и перед обучением lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f26a1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary, )\n",
    "# corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc2704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea86f15",
   "metadata": {},
   "source": [
    "### Загрузим и предобработаем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b4cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5793345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('wiki_data.txt', encoding=\"utf8\").read().splitlines()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ([normalize(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44c9eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf136d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text.split() for text in texts]\n",
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4) # threshold можно подбирать\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c87874",
   "metadata": {},
   "source": [
    "### Функция для получения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3408d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_metrics(model, corpus, texts, dictionary):\n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=num_topics, formatted=False):\n",
    "        topic = [word for word, _ in topic]\n",
    "        topics.append(topic)\n",
    "    coherence_model_lda = gensim.models.CoherenceModel(topics=topics,\n",
    "                                                       texts=texts,\n",
    "                                                       dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return np.exp2(-model.log_perplexity(corpus)), coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d2e50",
   "metadata": {},
   "source": [
    "### Стандартная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8a3098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary((text for text in texts))\n",
    "dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "lda_1 = gensim.models.LdaMulticore(corpus, \n",
    "                                 num_topics, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictionary, \n",
    "                                 passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d4b7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия: 188.5555754110799\n",
      "Когерентность: 0.4314441933977406\n"
     ]
    }
   ],
   "source": [
    "res = get_metrics(lda_1, corpus, texts, dictionary)\n",
    "print(f\"Перплексия: {res[0]}\\nКогерентность: {res[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24bbfab",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c369b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary((text for text in texts))\n",
    "dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "tf_idf_corpus = tfidf[corpus]\n",
    "\n",
    "lda_tfidf = gensim.models.LdaMulticore(tf_idf_corpus,\n",
    "                                        num_topics,\n",
    "                                        alpha='asymmetric',\n",
    "                                        id2word=dictionary,\n",
    "                                        passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ad6aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия: 1142.130824311733\n",
      "Когерентность: 0.4206214052183683\n"
     ]
    }
   ],
   "source": [
    "res = get_metrics(lda_tfidf, tf_idf_corpus, texts, dictionary)\n",
    "print(f\"Перплексия: {res[0]}\\nКогерентность: {res[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a32033",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c540426",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary((text for text in ngrammed_texts))\n",
    "dictionary.filter_extremes(no_above=0.05, no_below=10)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]\n",
    "\n",
    "lda_ngrams = gensim.models.LdaMulticore(corpus, \n",
    "                                     num_topics, # колиество тем\n",
    "                                     alpha='asymmetric',\n",
    "                                     id2word=dictionary, \n",
    "                                     passes=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d80b29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия: 231.5170435138144\n",
      "Когерентность: 0.45741584129128954\n"
     ]
    }
   ],
   "source": [
    "res = get_metrics(lda_ngrams, corpus, ngrammed_texts, dictionary)\n",
    "print(f\"Перплексия: {res[0]}\\nКогерентность: {res[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d00f9",
   "metadata": {},
   "source": [
    "### TfIdf + Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20da0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary((text for text in ngrammed_texts))\n",
    "dictionary.filter_extremes(no_above=0.05, no_below=10)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]\n",
    "\n",
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary, smartirs='lfc')\n",
    "corpus = tfidf[corpus]\n",
    "\n",
    "lda_tfidf_ngrams = gensim.models.LdaMulticore(corpus, \n",
    "                                 num_topics, # колиество тем\n",
    "                                 alpha='asymmetric',\n",
    "                                 id2word=dictionary, \n",
    "                                 passes=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46593e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия: 1163.4630347492553\n",
      "Когерентность: 0.3959155196392948\n"
     ]
    }
   ],
   "source": [
    "res = get_metrics(lda_tfidf_ngrams, corpus, ngrammed_texts, dictionary)\n",
    "print(f\"Перплексия: {res[0]}\\nКогерентность: {res[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51a623",
   "metadata": {},
   "source": [
    "### Анализ выделенных тем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b8f2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя \"\n",
    "\n",
    "def get_words(arr: list):\n",
    "    return \"\\n\\n\".join([\"\".join([c for c in x[1] if c in alph]) for x in arr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf8ebd",
   "metadata": {},
   "source": [
    "Стандартная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ccbfadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "премия  китайский  писатель  произведение  роман  н  язык  литература  э  литературный\n",
      "\n",
      "залив  река    связь  структура  побережье  впадать  значительный  берег  долина\n",
      "\n",
      "система  устройство  случай  плод  данные  например  ребёнок  суд    объект\n",
      "\n",
      "орудие  фраза  музыкальный  мотив  предложение  установка    вариант  основный  период\n",
      "\n",
      "й  аэропорт  значение    пространство    й  международный    \n",
      "\n",
      "германия  польский  памятник  проект  песня  берлин  мария  искусство  норвежский  фестиваль\n",
      "\n",
      "лагерь  газета  заключить    тысяча    политический  здание  среди  убить\n",
      "\n",
      "альбом  клуб  лига  команда  выпустить  песня  играть  чемпионат    матч\n",
      "\n",
      "клуб  команда  футбольный    чемпионат  сезон  участник  среди  соревнование  фамилия\n",
      "\n",
      "университет  колледж  соревнование  список  факультет  объект  образование  студент  канада  отделение\n",
      "\n",
      "штат  сезон  собрание  клуб  национальный  команда  финал  компания  конституция  серия\n",
      "\n",
      "фильм  роль  брат  жизнь  ребёнок  вместе  главный  театр  отец  чтобы\n",
      "\n",
      "  самолёт  день    атланта      бокс  чтобы  друг\n",
      "\n",
      "остров  станция  железнодорожный  километр  карта  северный  процесс  южный    метр\n",
      "\n",
      "департамент  дом  км  провинция  национальный  жужевать  численность  перепись  административный  сельсовет\n",
      "\n",
      "корабль  флот  лодка      космический  компания  сила  миссия  апрель\n",
      "\n",
      "река  фильм  национальный  км  бассейн    площадь  франция  парк  над\n",
      "\n",
      "бельгия  энергия  корпус  длина  система  если  роман  свет  можно  уровень\n",
      "\n",
      "день  сын  святой  праздник  пехотный  я  николай  орден  чин  полка\n",
      "\n",
      "г  н  метод  деятельность  период  качество  направление  э  процесс  далее\n"
     ]
    }
   ],
   "source": [
    "print(get_words(lda_1.print_topics()[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6da920",
   "metadata": {},
   "source": [
    "Осмысленная тема - альбом  клуб  лига  команда  выпустить  песня  играть  чемпионат. Про многие топики можно сказать, что сложно сходу определить их тему.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff0347",
   "metadata": {},
   "source": [
    "TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91ad8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матч  джордж  зелёный  ирландия  московский  университет  й  турнир  голос  заслуга\n",
      "\n",
      "конечный  круглый  изобразить  историк  каменный  комиссар  конгресс  здание  красивый  лишить\n",
      "\n",
      "индия  выставка  федеральный  швейцария  всемирный  суд  заметный  похожий  художник  статистика\n",
      "\n",
      "королевский  лондонский  церемония  должный  офицер  морской  есть  вооружённый  король  век\n",
      "\n",
      "конечный  круглый  изобразить  историк  каменный  комиссар  конгресс  здание  красивый  лишить\n",
      "\n",
      "бассейн  дворец  правитель  невозможно  упасть  крест  избежать  соорудить  главный  фигура\n",
      "\n",
      "вмс  военноморской  эсминец  тип  китайский  база  эксплуатация  честь    американский\n",
      "\n",
      "театр  роль  сергей  музыкальный  компания  шоу  театральный  санктпетербург  играть  руководство\n",
      "\n",
      "роль  сыграть  телесериал  сняться  фильм  сниматься  пилот    эпизод  постановка\n",
      "\n",
      "цикл  код  параметр  факт  стоять    случай  команда  производить  вызывать\n",
      "\n",
      "существо  живой  концепция  конституция  посёлок  республика  остров  главное  азия  полномочие\n",
      "\n",
      "горячий  острый  джек  можно  обычно  часто  общественный  доска  роберт  разнообразный\n",
      "\n",
      "командовать  миссия  григорий  заслуга  интернет  ум  чин  полковник  андрей  поход\n",
      "\n",
      "роман  королева  псевдоним  волна  село  премия  опубликовать  капитан  свет  нести\n",
      "\n",
      "сезон  занятой  таблица  александрович  украинский  сергей  обладатель  гонка  призёр  бронзовый\n",
      "\n",
      "укрепление  начальный  предполагать  обширный  добыча  глубина  сутки  выявить  университет  финал\n",
      "\n",
      "уезд  округ  городской  кнр  всемирный  россия  делиться  автономный  королева  провинция\n",
      "\n",
      "ботсвана  округ      австралия  фамилия  сидней  атлетика  численность  динамика\n",
      "\n",
      "остров  село  департамент  км  харьковский  посёлок  река  код  км  метр\n",
      "\n",
      "фильм  канада  спортсмен  значение  уезд  чемпионат  зимний  клуб  соревнование  экипаж\n"
     ]
    }
   ],
   "source": [
    "print(get_words(lda_tfidf.print_topics()[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8307f",
   "metadata": {},
   "source": [
    "Красивая тема - королевский  лондонский  церемония  должный  офицер  морской  есть  вооружённый  король  век. Кажется, что эта модель получше, чем предыдущая."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6207b",
   "metadata": {},
   "source": [
    "Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35dd8805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "корпус  дивизия  командир  полковник  командующий  операция  соединение  фронт  генералмайор  полка\n",
      "\n",
      "завод  посёлок  предприятие  производить    финансовый  совет  жена  париж  цикл\n",
      "\n",
      "клуб  матч  сборная  сезон  выиграть  лига  кубок  чемпионат  сыграть  игрок\n",
      "\n",
      "харьковскийобласть  нарасстояние  поперепись  мж  сельскийсовет  сезон  ниже  кодкоатуа  расположитьсело  шевченковскийрайон\n",
      "\n",
      "здание  подразделение  участок  иван  н  позиция  бой  немецкий  командование  отряд\n",
      "\n",
      "объект  передача  здание  культура  церковь  передать  собственность  российскийфедерация  закон  председатель\n",
      "\n",
      "залив  вода  применение  например  обычно  применяться  произойти  найти  поэтому  термин\n",
      "\n",
      "список  дворец  архитектор  здание  деревянный  ворота  строительство  архитектура  пётр  музей\n",
      "\n",
      "игрок  выпустить    разработать  доступный  австралия  режим  персонаж  образ  версия\n",
      "\n",
      "пара  джордж  ирландия  король  иногда    говорить  пол  правило  начаться\n",
      "\n",
      "эсминец  произвести  сражение  флот  корабль  камень  полный  должный  бой  враг\n",
      "\n",
      "монастырь  собор  община  строительство  озеро  восточный  северный  западный  башня  украина\n",
      "\n",
      "хутор  сельскийпоселение  епархия  дубовскийрайон  сопротивление  автомобильныйдорога  поселение  сельсовет  проживать  административныйцентр\n",
      "\n",
      "экономический  общество  мы  я  святой  институт  далее  праздник  экономика  конкурс\n",
      "\n",
      "гонка  сезон  выиграть  департамент  аргентина  победа  чемпионатмир  занять  административныйцентр  км\n",
      "\n",
      "взрыв  схема  мощность  л  александр  суд  возможность  минута    размер\n",
      "\n",
      "эксперимент  полёт  год  экипаж  тысяча  исследование  оценка  комплекс  тысячачеловек  составить\n",
      "\n",
      "уезд  округ  волость  губерния  бытьпреобразовать  кнр  городскойокруг  империя  бытьсоздать  зимнийолимпийский\n",
      "\n",
      "театр  соревнованиепо  сценарий  женщинапринимать  тяжёлыйатлетика  песня  я  смерть  ноне  фиджи\n",
      "\n",
      "турнир  свойистория  матч  разза  дисциплина  финал  сборная  соревнование  победитель  победа\n"
     ]
    }
   ],
   "source": [
    "print(get_words(lda_ngrams.print_topics()[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d575b8",
   "metadata": {},
   "source": [
    "Мне понравилась тема - корпус  дивизия  командир  полковник  командующий  операция  соединение  фронт  генералмайор  полка. По когерентности лучше всех эта модель. Качество тем довольно таки хорошее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f55649",
   "metadata": {},
   "source": [
    "TfIdf + Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fe81d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "памятник  германия  городской  линия  собор  польский  берлин  маршрут  поместить  сеть\n",
      "\n",
      "простой  дон  дерево  э    конструкция  вооружение  оружие  царь  эпоха\n",
      "\n",
      "курс  первыйсекретарь    организовать  сотрудничатьс  депутатверховный  кпсс  считатьчто  николаевич  созыв\n",
      "\n",
      "соединение  анализ  определение  метод  изучение  академиянаука  учёный  завод  л  исследование\n",
      "\n",
      "анатолий  тренер  первенство  бронзовыйпризёр  фестиваль  сборная  женский    чемпионмир  \n",
      "\n",
      "владимир  майор  я  париж  вы  смочь  состояние  найти  расследование  самоубийство\n",
      "\n",
      "курс  первыйсекретарь    организовать  сотрудничатьс  депутатверховный  кпсс  считатьчто  николаевич  созыв\n",
      "\n",
      "курс  первыйсекретарь    организовать  сотрудничатьс  депутатверховный  кпсс  считатьчто  николаевич  созыв\n",
      "\n",
      "курс  первыйсекретарь    организовать  сотрудничатьс  депутатверховный  кпсс  считатьчто  николаевич  созыв\n",
      "\n",
      "кнр  свидетель  китай  китайский  религиозный  политика  практика  религия  приказ  свобода\n",
      "\n",
      "успеть  сценарий  великийотечественный  снять  идти  весна  захватить  григорий  оккупировать  опасный\n",
      "\n",
      "миссия  оборудование  курс  технологический  купить  комсомольский  великобритания  отечественныйвойна  подразделение  сценарий\n",
      "\n",
      "капитан  лист  журнал  мм  роман  кпсс  ли  альбом  вокзал  б\n",
      "\n",
      "метр  другдруг  архипелаг  архангельскийобласть  приморскийрайон  старт  священник  северныйчасть  чёрный  осуществить\n",
      "\n",
      "л  объём  двигатель  европейский  модель  турнир  точный    швейцария  карьера\n",
      "\n",
      "каждыйзаезд  бельгия  сильныйэкипаж  следующийраунд  хорошийэкипаж  проходитьнесколько  странасостоять  пункт  бельгияпринимать  выходить\n",
      "\n",
      "  видрод    академиянаука  основание  род    академик  сср  доктор\n",
      "\n",
      "правило  съёмка  михаилович  некий  вероятно  принести  судьба  неизвестный  некоторыйвремя  скончаться\n",
      "\n",
      "уезд  метр  департамент  округ  км  семейство  аргентина  лист  юг  административныйцентр\n",
      "\n",
      "значение  зимнийолимпийский  соревнованиепо  клуб  посёлок  сборнаястрана  второйраз  турнир  альбом  песня\n"
     ]
    }
   ],
   "source": [
    "print(get_words(lda_tfidf_ngrams.print_topics()[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c674a",
   "metadata": {},
   "source": [
    "Понравилась тема - анатолий  тренер  первенство  бронзовыйпризёр  фестиваль  сборная  женский    чемпионмир  . Странно, что 3 раза повторяется один и тот же набор слов (курс  первыйсекретарь    организовать  сотрудничатьс  депутатверховный  кпсс  считатьчто  николаевич  созыв) - так сработал алгоритм. Кажется, эта модель на глаз точно не лучше 2 предыдущих."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614972a2",
   "metadata": {},
   "source": [
    "Думаю, что модель ngrams лучше всех - мне так показалось на глаз. По метрикам выигрывает стандартный алгоритм и n-граммы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebac11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
